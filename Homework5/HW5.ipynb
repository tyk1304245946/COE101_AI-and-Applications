{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[[2, -5, 3, 1, 5, 0],\n",
    "     [8, 1, 0, 3, 3, 3],\n",
    "     [-1, -1, -2, -1, -6, 0],\n",
    "     [-3, 0, 6, -6, -1, 8],\n",
    "     [0, -5, 1, 2, 1, -4],\n",
    "     [-1, -3, 2, -3, -2, -4]]]\n",
    "\n",
    "w1 = [[1, -1, 0],\n",
    "      [-1, 2, -3],\n",
    "      [0, -3, 1]]\n",
    "\n",
    "w1_flipped = [[1, -3, 0],\n",
    "              [-3, 2, -1],\n",
    "              [0, -1, 1]]\n",
    "\n",
    "w2_1 = [[-2, 1],\n",
    "        [0, 2]]\n",
    "\n",
    "w2_1_flipped = [[2, 0],\n",
    "                [1, -2]]\n",
    "\n",
    "w2_2 = [[-2, 0],\n",
    "        [-1, 0]]\n",
    "\n",
    "w2_2_flipped = [[0, -1],\n",
    "                [0, -2]]\n",
    "\n",
    "w2_3 = [[0, -1],\n",
    "        [2, -1]]\n",
    "\n",
    "w2_3_flipped = [[-1, 2],\n",
    "                [-1, 0]]\n",
    "\n",
    "w3 = [[-1, 1, -5],\n",
    "      [2, -1, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 1, kernel_size=(3, 3), stride=1)\n",
    "        self.conv2 = nn.Conv2d(1, 3, kernel_size=(2, 2), stride=1)\n",
    "        self.full = nn.Linear(3, 2)\n",
    "\n",
    "        # Initialize weights\n",
    "        # 卷积核需要翻转\n",
    "        w1_flip = w1[::-1][::-1]\n",
    "        self.conv1.weight.data = torch.tensor(w1_flipped).float().view(1, 1, 3, 3)\n",
    "        self.conv2.weight.data = torch.tensor([w2_1_flipped, w2_2_flipped, w2_3_flipped]).float().view(3, 1, 2, 2)\n",
    "        self.full.weight.data = torch.tensor(w3).float().view(2, 3)\n",
    "        # Initialize biases\n",
    "        self.conv1.bias.data = torch.tensor([0]).float()\n",
    "        self.conv2.bias.data = torch.tensor([0, 0, 0]).float()\n",
    "        self.full.bias.data = torch.tensor([0, 0]).float()\n",
    "\n",
    "    def forward_print(self, x):\n",
    "        x = self.conv1(x)\n",
    "        print(\"conv1\")\n",
    "        print(x)\n",
    "\n",
    "        x = F.relu(x)\n",
    "        print(\"relu\")\n",
    "        print(x)\n",
    "\n",
    "        x = F.max_pool2d(x, kernel_size=(2, 2), stride=2, padding=0)\n",
    "        print(\"maxpool\")\n",
    "        print(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        print(\"conv2\")\n",
    "        print(x)\n",
    "\n",
    "        x = F.relu(x)\n",
    "        print(\"relu\")\n",
    "        print(x)\n",
    "\n",
    "        x = self.full(x.view(x.size(0), -1))\n",
    "        print(\"full\")\n",
    "        print(x)\n",
    "        \n",
    "        # softmax\n",
    "        x = F.softmax(x, dim=1)\n",
    "        print(\"softmax\")\n",
    "        print(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=(2, 2), stride=2, padding=0)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.full(x.view(x.size(0), -1))\n",
    "        # softmax\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "[[[2, -5, 3, 1, 5, 0], [8, 1, 0, 3, 3, 3], [-1, -1, -2, -1, -6, 0], [-3, 0, 6, -6, -1, 8], [0, -5, 1, 2, 1, -4], [-1, -3, 2, -3, -2, -4]]]\n",
      "Input shape: torch.Size([1, 1, 6, 6])\n",
      "Input tensor:\n",
      "tensor([[[[ 2., -5.,  3.,  1.,  5.,  0.],\n",
      "          [ 8.,  1.,  0.,  3.,  3.,  3.],\n",
      "          [-1., -1., -2., -1., -6.,  0.],\n",
      "          [-3.,  0.,  6., -6., -1.,  8.],\n",
      "          [ 0., -5.,  1.,  2.,  1., -4.],\n",
      "          [-1., -3.,  2., -3., -2., -4.]]]])\n",
      "Weights conv1:\n",
      "[[1, -1, 0], [-1, 2, -3], [0, -3, 1]]\n",
      "Weights conv2:\n",
      "[[-2, 1], [0, 2]] [[-2, 0], [-1, 0]] [[0, -1], [2, -1]]\n",
      "Weights full:\n",
      "[[-1, 1, -5], [2, -1, -1]]\n",
      "Bias conv1:\n",
      "[0]\n",
      "Bias conv2:\n",
      "[0, 0, 0]\n",
      "Bias full:\n",
      "[0]\n",
      "Output:\n",
      "tensor([[0.0025, 0.9975]], grad_fn=<SoftmaxBackward0>)\n",
      "Output shape: torch.Size([1, 2])\n",
      "Output tensor:\n",
      "[[0.00247262 0.9975274 ]]\n",
      "Expected output:\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\")\n",
    "print(x)\n",
    "\n",
    "x = torch.tensor(x).float().view(1, 1, 6, 6)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Input tensor:\")\n",
    "print(x)\n",
    "\n",
    "print(\"Weights conv1:\")\n",
    "print(w1)\n",
    "print(\"Weights conv2:\")\n",
    "print(w2_1, w2_2, w2_3)\n",
    "print(\"Weights full:\")\n",
    "print(w3)\n",
    "\n",
    "print(\"Bias conv1:\")\n",
    "print([0])\n",
    "print(\"Bias conv2:\")\n",
    "print([0, 0, 0])\n",
    "\n",
    "print(\"Bias full:\")\n",
    "print([0])\n",
    "\n",
    "print(\"Output:\")\n",
    "model = cnn()\n",
    "print(model(x))\n",
    "print(\"Output shape:\", model(x).shape)\n",
    "print(\"Output tensor:\")\n",
    "print(model(x).detach().numpy())\n",
    "print(\"Expected output:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "conv1\n",
      "tensor([[[[ -6., -19.,  -2., -14.],\n",
      "          [ 14., -11.,   6.,  -6.],\n",
      "          [ 11.,  24., -29.,  20.],\n",
      "          [ -9.,  -8.,  25.,  -5.]]]], grad_fn=<ConvolutionBackward0>)\n",
      "relu\n",
      "tensor([[[[ 0.,  0.,  0.,  0.],\n",
      "          [14.,  0.,  6.,  0.],\n",
      "          [11., 24.,  0., 20.],\n",
      "          [ 0.,  0., 25.,  0.]]]], grad_fn=<ReluBackward0>)\n",
      "maxpool\n",
      "tensor([[[[14.,  6.],\n",
      "          [24., 25.]]]], grad_fn=<MaxPool2DWithIndicesBackward0>)\n",
      "conv2\n",
      "tensor([[[[  2.]],\n",
      "\n",
      "         [[-56.]],\n",
      "\n",
      "         [[-26.]]]], grad_fn=<ConvolutionBackward0>)\n",
      "relu\n",
      "tensor([[[[2.]],\n",
      "\n",
      "         [[0.]],\n",
      "\n",
      "         [[0.]]]], grad_fn=<ReluBackward0>)\n",
      "full\n",
      "tensor([[-2.,  4.]], grad_fn=<AddmmBackward0>)\n",
      "softmax\n",
      "tensor([[0.0025, 0.9975]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0025, 0.9975]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出每一层的结果\n",
    "print(\"Output:\")\n",
    "model.forward_print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
